{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "from multiprocessing import Pool\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from torch._C import dtype\n",
    "from typing import Dict\n",
    "from models.siren_model import Siren\n",
    "from models.very_tiny_nerf_model import VeryTinyNerfModel\n",
    "import deepCABAC\n",
    "from torchinfo import summary\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DTYPE_BIT_SIZE: Dict[dtype, int] = {\n",
    "    torch.float32: 32,\n",
    "    torch.float: 32,\n",
    "    torch.float64: 64,\n",
    "    torch.double: 64,\n",
    "    torch.float16: 16,\n",
    "    torch.half: 16,\n",
    "    torch.bfloat16: 16,\n",
    "    torch.complex32: 32,\n",
    "    torch.complex64: 64,\n",
    "    torch.complex128: 128,\n",
    "    torch.cdouble: 128,\n",
    "    torch.uint8: 8,\n",
    "    torch.int8: 8,\n",
    "    torch.int16: 16,\n",
    "    torch.short: 16,\n",
    "    torch.int32: 32,\n",
    "    torch.int: 32,\n",
    "    torch.int64: 64,\n",
    "    torch.long: 64,\n",
    "    torch.bool: 1\n",
    "}\n",
    "\n",
    "def model_size_in_bits(model):\n",
    "    \"\"\"Calculate total number of bits to store `model` parameters and buffers.\"\"\"\n",
    "    return sum(sum(t.nelement() * DTYPE_BIT_SIZE[t.dtype] for t in tensors)\n",
    "               for tensors in (model.parameters(), model.buffers()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clamp_image(img):\n",
    "    \"\"\"Clamp image values to like in [0, 1] and convert to unsigned int.\n",
    "    Args:\n",
    "        img (torch.Tensor):\n",
    "    \"\"\"\n",
    "    # Values may lie outside [0, 1], so clamp input\n",
    "    img_ = torch.clamp(img, 0., 1.)\n",
    "    # Pixel values lie in {0, ..., 255}, so round float tensor\n",
    "    return torch.round(img_ * 255) / 255.\n",
    "    \n",
    "def psnr(img1, img2):\n",
    "    \"\"\"Calculates PSNR between two images.\n",
    "    Args:\n",
    "        img1 (torch.Tensor):\n",
    "        img2 (torch.Tensor):\n",
    "    \"\"\"\n",
    "    return 20. * np.log10(1.) - 10. * (img1 - img2).detach().pow(2).mean().log10().to('cpu').item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_minibatches(inputs: torch.Tensor, chunksize: Optional[int] = 1024 * 8):\n",
    "  r\"\"\"\n",
    "  Each element of the list (except possibly the last) has dimension `0` of length\n",
    "  `chunksize`.\n",
    "  \"\"\"\n",
    "  return [inputs[i:i + chunksize] for i in range(0, inputs.shape[0], chunksize)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "CUDA version: 11.2\n",
      "\n",
      "Tesla T4\n",
      "Memory Usage:\n",
      "Allocated: 0.0 GB\n",
      "Cached:    0.0 GB\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)\n",
    "print('CUDA version:', torch.version.cuda)\n",
    "print()\n",
    "\n",
    "#Additional Info when using cuda\n",
    "if device.type == 'cuda':\n",
    "    print(torch.cuda.get_device_name(0))\n",
    "    print('Memory Usage:')\n",
    "    print('Allocated:', round(torch.cuda.memory_allocated(0)/1024**3, 1), 'GB')\n",
    "    print('Cached:   ', round(torch.cuda.memory_reserved(0)/1024**3, 1), 'GB')\n",
    "\n",
    "torch.set_default_tensor_type('torch.cuda.FloatTensor' if torch.cuda.is_available() else 'torch.FloatTensor')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cap = cv2.VideoCapture(\"../datasets/00003.mp4\")\n",
    "cap = cv2.VideoCapture(\"../datasets/fireworks_128.mp4\")\n",
    "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "# total_frames = 10\n",
    "\n",
    "\n",
    "def complex_vid(width=100, height=100, frames=100):\n",
    "  \"\"\"Peak complexity video. Random pixel values for all coords at each frame.\"\"\"\n",
    "  return torch.rand(frames, width, height, 3)\n",
    "\n",
    "def get_frame(idx):\n",
    "  r\"\"\" Get the RGB tensor of a specific frame in the video.\n",
    "  \"\"\"\n",
    "  cap.set(cv2.CAP_PROP_POS_FRAMES, idx)\n",
    "  success, img = cap.read()\n",
    "  if not success:\n",
    "    print(\"Failed to load frame at index \" + str(idx))\n",
    "  return torch.from_numpy(np.float32(img) / 255)\n",
    "\n",
    "frames = torch.stack([get_frame(i) for i in range(total_frames)])\n",
    "frames = frames.to(device)\n",
    "# frames = complex_vid(frames=100)\n",
    "# total_frames = 100\n",
    "# width = 100\n",
    "# height = 100\n",
    "# fps = 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xs_and_ys(width, height, frame_ind):\n",
    "    r\"\"\" Construct (x, y, f) tuples.\n",
    "    \"\"\"\n",
    "\n",
    "    coordinates = torch.ones([height,width]).nonzero(as_tuple=False).float()\n",
    "\n",
    "\n",
    "    #Assuming the image is square is necessary for this nice vector operation\n",
    "    #Change if we use non-square image\n",
    "    coordinates = coordinates/ (height - 1) - 0.5\n",
    "\n",
    "    fill_val =  frame_ind/(total_frames -1) - 0.5\n",
    "    frame_indicies = torch.full((coordinates.shape[0], 1), fill_val)\n",
    "    coordinates = torch.cat([coordinates, frame_indicies], -1)\n",
    " \n",
    "    coordinates *= 2\n",
    "    return coordinates\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def positional_encoding(\n",
    "    tensor, num_encoding_functions = [6,6,6], std_dev = 1.4, include_input=True, log_sampling=True\n",
    ") -> torch.Tensor:\n",
    "    r\"\"\"Apply positional encoding to the input.\n",
    "\n",
    "    Args:\n",
    "    tensor (torch.Tensor): Input tensor to be positionally encoded.\n",
    "    num_encoding_functions (optional, int): Number of encoding functions used to\n",
    "        compute a positional encoding (default: 6).\n",
    "    std_dev (optional, int): Scale parameter/standard deviation, replaces the default two used in Nerf\n",
    "    include_input (optional, bool): Whether or not to include the input in the\n",
    "        computed positional encoding (default: True).\n",
    "    log_sampling (optional, bool): Sample logarithmically in frequency space, as\n",
    "        opposed to linearly (default: True).\n",
    "\n",
    "    Returns:\n",
    "    (torch.Tensor): Positional encoding of the input tensor.\n",
    "    \"\"\"\n",
    "    # TESTED\n",
    "    # Trivially, the input tensor is added to the positional encoding.\n",
    "\n",
    "    encoding = [tensor] if include_input else []\n",
    "\n",
    "    # Now, encode the input using a set of high-frequency functions and append the\n",
    "    # resulting values to the encoding.\n",
    "    frequency_bands = None\n",
    "    if log_sampling:\n",
    "        frequency_bands =[ std_dev ** torch.linspace(\n",
    "            0.0,\n",
    "            n - 1,\n",
    "            n,\n",
    "            dtype=tensor.dtype,\n",
    "            device=tensor.device,\n",
    "        ) for n in num_encoding_functions]\n",
    "\n",
    "    else:\n",
    "        frequency_bands = [ torch.linspace(\n",
    "            std_dev ** 0.0,\n",
    "            std_dev ** (n - 1),\n",
    "            n,\n",
    "            dtype=tensor.dtype,\n",
    "            device=tensor.device,\n",
    "        ) for n in num_encoding_functions ]\n",
    "        \n",
    "    max_enc_len = np.max(num_encoding_functions)    \n",
    "    for i in range(0, max_enc_len):\n",
    "            for func in [torch.sin, torch.cos]:\n",
    "                for j in range(0, len(num_encoding_functions)):\n",
    "                    freq_band = frequency_bands[j]\n",
    "                    if i < len(freq_band):\n",
    "                        encoding.append(func(tensor[:, j:j+1] * freq_band[i]))\n",
    "                   \n",
    "\n",
    "    # Special case, for no positional encoding\n",
    "    if len(encoding) == 1:\n",
    "        return encoding[0]\n",
    "    else:\n",
    "        return torch.cat(encoding, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian_encoding(tensor, num_encoding_functions=[6, 6, 6], std_dev=1.4, include_input=True):\n",
    "\n",
    "    encoding = [tensor] if include_input else []\n",
    "\n",
    "    frequency_bands = [torch.linspace(\n",
    "            0.0,\n",
    "            n - 1,\n",
    "            n,\n",
    "            dtype=tensor.dtype,\n",
    "            device=tensor.device,\n",
    "        ) for n in num_encoding_functions]\n",
    "\n",
    "    max_enc_len = np.max(num_encoding_functions)\n",
    "    for i in range(0, max_enc_len):\n",
    "            for j in range(0, len(num_encoding_functions)):\n",
    "                freq_band = frequency_bands[j]\n",
    "                if i < len(freq_band):\n",
    "                    encoding.append(torch.exp(-torch.pow((freq_band[i] - tensor[:, j:j+1]), 2) / (2 * std_dev**2)))\n",
    "\n",
    "    # Special case, for no positional encoding\n",
    "    if len(encoding) == 1:\n",
    "        return encoding[0]\n",
    "    else:\n",
    "        return torch.cat(encoding, dim=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded = {}\n",
    "def one_iter_npc(width, height, model, frame_ind, encoding_fn, get_minibatches_fn):\n",
    "\n",
    "\n",
    "  if not frame_ind in encoded:\n",
    "    pts = xs_and_ys(width, height, frame_ind)\n",
    "    encoded_pts = encoding_fn(pts)\n",
    "    encoded[frame_ind] = encoded_pts\n",
    "  else:\n",
    "    encoded_pts = encoded[frame_ind]\n",
    "  \n",
    "  rgb_flat = model(encoded_pts)\n",
    "  rgb = torch.reshape(rgb_flat, [height, width, 3])\n",
    "  return rgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def output_video(fps, width: int, height: int, encode, get_minibatches):\n",
    "  r\"\"\"Build the final video from the trained model.\"\"\"\n",
    "  out = cv2.VideoWriter('output_video.mp4', cv2.VideoWriter_fourcc(*'mp4v'), fps, (width, height))\n",
    "\n",
    "  def output_v(start_frame, end_frame, model):\n",
    "    for f in range(start_frame, end_frame):\n",
    "        rgb_predicted = clamp_image(one_iter_npc(width, height, model,\n",
    "                                     f, encode,\n",
    "                                     get_minibatches))\n",
    "\n",
    "        rgb_out = cv2.normalize(src=rgb_predicted.detach().cpu().numpy(), dst=None, alpha=0, beta=255,\n",
    "                                norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_8U)\n",
    "        out.write(rgb_out)\n",
    "    return lambda: out.release()\n",
    "\n",
    "  return output_v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_new_chunk():\n",
    "  # model = VeryTinyNerfModel(num_encoding_functions=num_encoding_functions,\n",
    "  #                           num_hidden_layers=num_hidden_layers, filter_size=filter_size)\n",
    "\n",
    "  model = Siren(\n",
    "        dim_in=3,\n",
    "        dim_hidden=filter_size,\n",
    "        dim_out=3,\n",
    "        num_layers=num_hidden_layers,\n",
    "        final_activation=torch.nn.Identity(),\n",
    "        w0_initial=30.0,\n",
    "        w0=30.0,\n",
    "        num_encoding_functions = num_encoding_functions,\n",
    "    )\n",
    "\n",
    "  l1_w = 1e-6\n",
    "\n",
    "\n",
    "  print(\"Model size: {:2f} MB\".format(1e-6 * model_size_in_bits(model) / 8))\n",
    "  print(f\"Model size in bits: {model_size_in_bits(model)}\")\n",
    "  model.to(device)\n",
    "\n",
    "  optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "  # Lists to log metrics etc.\n",
    "  psnrs = []\n",
    "  iternums = []\n",
    "\n",
    "  all_psnrs = {}\n",
    "\n",
    "\n",
    "  def training_loop(start_frame, end_frame, num_iters = 500, mean_psnr_cutoff = 30):\n",
    "    nonlocal model \n",
    "    nonlocal optimizer\n",
    "    nonlocal iternums\n",
    "    nonlocal all_psnrs\n",
    "    nonlocal l1_w\n",
    "\n",
    "    chunk_frames = end_frame - start_frame\n",
    "    test_frame = end_frame - 1\n",
    "\n",
    "    print(\"Start frame: \" + str(start_frame) + \", end frame: \" + str(end_frame))\n",
    "    print(\"Total frames: \" + str(chunk_frames))\n",
    "\n",
    "    for i in range(num_iters + 1):\n",
    "      with torch.cuda.amp.autocast():\n",
    "        # Randomly pick a frame as the target\n",
    "        target_frame_idx = np.random.randint(start_frame, end_frame)\n",
    "\n",
    "        target_img = frames[target_frame_idx] # get_frame(target_frame_idx)\n",
    "        \n",
    "        rgb_predicted = one_iter_npc(width, height, model,\n",
    "                                    target_frame_idx, encode,\n",
    "                                    get_minibatches)\n",
    "\n",
    "        # Compute mean-squared error between the predicted and target images. Backprop!\n",
    "        l1_reg = l1_w * torch.abs(torch.cat([p.view(-1) for p in model.parameters()])).sum()\n",
    "\n",
    "        loss = torch.nn.functional.mse_loss(rgb_predicted, target_img) + l1_reg\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        clamped_rgp_predicted = clamp_image(rgb_predicted)\n",
    "\n",
    "        img_psnr = psnr(target_img, clamped_rgp_predicted)\n",
    "      \n",
    "        all_psnrs[target_frame_idx] = img_psnr.item()\n",
    "\n",
    "        # Display images/plots/stats\n",
    "        if (i > 0) and (i % display_every == 0):\n",
    "          # Render the held-out view\n",
    "          \n",
    "          test_frame_img = frames[test_frame] # get_frame(test_frame)\n",
    "          rgb_predicted = clamp_image(one_iter_npc(width, height, model,\n",
    "                                      test_frame, encode,\n",
    "                                      get_minibatches))\n",
    "\n",
    "          held_out_frame_psnr = psnr(test_frame_img, rgb_predicted)\n",
    "          mean_psnr = np.mean(list(all_psnrs.values()))\n",
    "          median_psnr = np.median(list(all_psnrs.values()))\n",
    "          print(\"Loss:\", loss.item(),\"Frame PSNR:\", held_out_frame_psnr,\"Mean PSNR:\", mean_psnr, \"Median PSNR:\", median_psnr)\n",
    "\n",
    "          iternums.append(i)\n",
    "          plt.figure(figsize=(10, 4))\n",
    "          plt.subplot(121)\n",
    "          plt.imshow(rgb_predicted.detach().cpu().numpy().astype(float))\n",
    "          plt.title(f\"Iteration {i}\")\n",
    "          plt.subplot(122)\n",
    "          plt.imshow(test_frame_img.detach().cpu().numpy().astype(float))\n",
    "          # plt.plot(iternums, psnrs)\n",
    "          plt.title(\"Original\")\n",
    "          plt.show()\n",
    "        \n",
    "    return model\n",
    "\n",
    "  return training_loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_chunk(tup):\n",
    "    return get_new_chunk()(start_frame = tup[0], end_frame = tup[1], num_iters = tup[2], mean_psnr_cutoff = tup[3])\n",
    "\n",
    "\n",
    "def chunk_processing(total_frames, outputter, frames_per_chunk, max_iters, psnr_cutoff, train_loop= None):\n",
    "\n",
    "    start_index = 0 \n",
    "\n",
    "    params = []\n",
    "    models = []\n",
    "    for i in range(0, total_frames, frames_per_chunk):\n",
    "        models.append(get_new_chunk()(i, min(total_frames, i+frames_per_chunk), max_iters, psnr_cutoff) )\n",
    "\n",
    "    for i in range(0, len(models)):\n",
    "        start_index = i*frames_per_chunk\n",
    "        release_out = outputter(start_index, min(total_frames, start_index+frames_per_chunk), models[i])\n",
    "    \n",
    "    return release_out, models\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video dims: 128x128\n",
      "Framerate: 25.0\n",
      "Dim_in: 323\n",
      "Model size: 0.365580 MB\n",
      "Model size in bits: 2924640\n",
      "Start frame: 0, end frame: 15\n",
      "Total frames: 15\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Parameters for NPC training\n",
    "\"\"\"\n",
    "\n",
    "num_hidden_layers = 4\n",
    "filter_size = 128\n",
    "std_dev = 1.4\n",
    "# Number of functions used in the positional encoding (Be sure to update the\n",
    "# model if this number changes).\n",
    "num_encoding_functions = [64, 64, 32]\n",
    "\n",
    "\n",
    "# Specify encoding function.\n",
    "def encode(x): return positional_encoding(\n",
    "    x, num_encoding_functions=num_encoding_functions, std_dev = std_dev, include_input=True, log_sampling=True)\n",
    "# def encode(x): return gaussian_encoding(\n",
    "#     x, num_encoding_functions=num_encoding_functions, std_dev=0.0003, include_input=True)\n",
    "# def encode(x): return x\n",
    "\n",
    "\n",
    "# Optimizer parameters\n",
    "lr = 2e-5\n",
    "\n",
    "seed_iters = 500\n",
    "baseline_iters = 250\n",
    "num_iters = 25000\n",
    "\n",
    "#Misc parameters\n",
    "display_every = 5000  # Number of iters after which stats are displayed\n",
    "\n",
    "\"\"\"\n",
    "Train-Eval-Repeat!\n",
    "\"\"\"\n",
    "\n",
    "# Seed RNG, for repeatability\n",
    "seed = 1337\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "\n",
    "outputter = output_video(fps, width, height, encode, get_minibatches)\n",
    "\n",
    "print(\"Video dims: \" + str(width) + \"x\" + str(height))\n",
    "print(\"Framerate: \" + str(fps))\n",
    "\n",
    "initial_chunk_size = 2\n",
    "chunk_increment = 2\n",
    "\n",
    "\n",
    "# Horrible idea, absolute standards make the algorithm only compress two frames at a time\n",
    "# For most of the sections\n",
    "# mean_psnr_one_fram, train_loop = get_baseline_psnr(total_frames, initial_chunk_size, seed_iters)\n",
    "# print(mean_psnr_one_fram)\n",
    "\n",
    "frames_per_chunk = 15 # 24\n",
    "release_out, models = chunk_processing(total_frames=total_frames, outputter=outputter, frames_per_chunk=frames_per_chunk, max_iters=num_iters, psnr_cutoff = 40.0)\n",
    "# release_out = chunk_processing(total_frames, outputter, chunk_increment = chunk_increment , seed_iters = seed_iters, baseline_iters = baseline_iters, iters_per_frame = iters_per_frame, initial_chunk_size = initial_chunk_size, baseline_mean_psnr_percentage = 0.9)\n",
    "\n",
    "\n",
    "print('Done training. Storing output...')\n",
    "release_out()\n",
    "print(\"Output complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compressed size: 0.048472 MB\n",
      "Compressed size: 0.045162 MB\n",
      "Dim_in: 323\n",
      "Dim_in: 323\n",
      "Mean PSNR: 27.68512725830078 Median PSNR: 27.68512725830078\n",
      "Mean PSNR: 28.491586446762085 Median PSNR: 28.491586446762085\n",
      "Mean PSNR: 28.96071990331014 Median PSNR: 29.29804563522339\n",
      "Mean PSNR: 29.202473759651184 Median PSNR: 29.59851622581482\n",
      "Mean PSNR: 29.317337036132812 Median PSNR: 29.776790142059326\n",
      "Mean PSNR: 29.29075002670288 Median PSNR: 29.537417888641357\n",
      "Mean PSNR: 29.321529184068954 Median PSNR: 29.50620412826538\n",
      "Mean PSNR: 29.15383070707321 Median PSNR: 29.402124881744385\n",
      "Mean PSNR: 29.189258416493733 Median PSNR: 29.47268009185791\n",
      "Mean PSNR: 29.19486355781555 Median PSNR: 29.38536286354065\n",
      "Mean PSNR: 29.215681769631125 Median PSNR: 29.423863887786865\n",
      "Mean PSNR: 29.13794994354248 Median PSNR: 29.13794994354248\n",
      "Mean PSNR: 28.922892808914185 Median PSNR: 28.922892808914185\n",
      "Mean PSNR: 28.991137345631916 Median PSNR: 29.127626419067383\n",
      "Mean PSNR: 28.858569860458374 Median PSNR: 28.917731046676636\n",
      "Mean PSNR: 29.507312774658203 Median PSNR: 29.127626419067383\n",
      "Mean PSNR: 30.076486269632976 Median PSNR: 29.13278818130493\n",
      "Mean PSNR: 30.405266625540598 Median PSNR: 29.13794994354248\n",
      "Mean PSNR: 30.734125673770905 Median PSNR: 30.6201171875\n",
      "Mean PSNR: 30.91255161497328 Median PSNR: 32.10228443145752\n",
      "Mean PSNR: 30.91255161497328 Median PSNR: 32.10228443145752\n"
     ]
    }
   ],
   "source": [
    "\n",
    "interv = 0.1\n",
    "stepsize = 3**(-0.5*13)\n",
    "stepsize_other = 3**(-0.5*17)\n",
    "_lambda = 0.\n",
    "\n",
    "for i in range(len(models)):\n",
    "    encoder = deepCABAC.Encoder()\n",
    "\n",
    "    for name, param in models[i].state_dict().items():\n",
    "        if '.num_batches_tracked' in name:\n",
    "            continue\n",
    "        param = param.cpu().numpy()\n",
    "        if '.weight' in name:\n",
    "            encoder.encodeWeightsRD(param, interv, stepsize, _lambda)\n",
    "        else:\n",
    "            encoder.encodeWeightsRD(param, interv, stepsize_other, _lambda)\n",
    "\n",
    "    stream = encoder.finish().tobytes()\n",
    "    print(\"Compressed size: {:2f} MB\".format(1e-6 * len(stream)))\n",
    "    with open(f\"weights_{i}.bin\", 'wb') as f:\n",
    "        f.write(stream)\n",
    "\n",
    "decoded_models = []\n",
    "for i in range(len(models)):\n",
    "        \n",
    "    # decoding\n",
    "    model = Siren(\n",
    "        dim_in=3,\n",
    "        dim_hidden=filter_size,\n",
    "        dim_out=3,\n",
    "        num_layers=num_hidden_layers,\n",
    "        final_activation=torch.nn.Identity(),\n",
    "        w0_initial=30.0,\n",
    "        w0=30.0,\n",
    "        num_encoding_functions = num_encoding_functions,\n",
    "    )\n",
    "\n",
    "    decoder = deepCABAC.Decoder()\n",
    "\n",
    "    with open(f\"weights_{i}.bin\", 'rb') as f:\n",
    "        stream = f.read()\n",
    "\n",
    "    decoder.getStream(np.frombuffer(stream, dtype=np.uint8))\n",
    "    state_dict = model.state_dict()\n",
    "\n",
    "    for name in state_dict.keys():\n",
    "        if '.num_batches_tracked' in name:\n",
    "            continue\n",
    "        param = decoder.decodeWeights()\n",
    "        state_dict[name] = torch.tensor(param)\n",
    "    decoder.finish()\n",
    "    model.load_state_dict(state_dict)\n",
    "    decoded_models.append(model)\n",
    "\n",
    "out = cv2.VideoWriter('output_video_compressed.mp4', cv2.VideoWriter_fourcc(\n",
    "    *'mp4v'), fps, (width, height))\n",
    "\n",
    "all_psnrs = []\n",
    "for i in range(total_frames):\n",
    "  rgb_predicted = clamp_image(torch.reshape(\n",
    "      decoded_models[int(i/frames_per_chunk)](encoded[i]), [height, width, 3]))\n",
    "\n",
    "  img_psnr = psnr(frames[i], rgb_predicted)\n",
    "  all_psnrs.append(img_psnr.item())\n",
    "\n",
    "  mean_psnr = np.mean(all_psnrs)\n",
    "  median_psnr = np.median(all_psnrs)\n",
    "  print(\"Mean PSNR:\", mean_psnr, \"Median PSNR:\", median_psnr)\n",
    "\n",
    "  if i == 10:\n",
    "      all_psnrs = []\n",
    "\n",
    "  rgb_out = cv2.normalize(src=rgb_predicted.detach().cpu().numpy(), dst=None, alpha=0, beta=255,\n",
    "                          norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_8U)\n",
    "  out.write(rgb_out)\n",
    "\n",
    "out.release()\n",
    "\n",
    "mean_psnr = np.mean(all_psnrs)\n",
    "median_psnr = np.median(all_psnrs)\n",
    "print(\"Mean PSNR:\", mean_psnr, \"Median PSNR:\", median_psnr)\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f2b8b32e4c53990335ef705a45605f5affc8b2c65b21767962c9c4ac82ce75bf"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('npc': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
